{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test LoRA en Google Colab (estable)\n",
        "\n",
        "Este notebook carga tu adapter LoRA y genera un ejercicio directamente en Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Instalar dependencias (versiones compatibles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q --upgrade \"transformers>=4.48.0\" \"trl==0.11.4\" \"peft>=0.12.0\" \"datasets>=2.20.0\" \"accelerate>=0.31.0\" \"bitsandbytes>=0.43.0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:** si acabas de instalar, reinicia el runtime y vuelve a correr desde aqui.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Subir tu adapter LoRA (zip)\n",
        "Sube `qwen3-jupyter-lora.zip`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "zip_name = [k for k in uploaded.keys() if k.endswith('.zip')][0]\n",
        "with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "    z.extractall('model')\n",
        "print('model files:', os.listdir('model'))\n",
        "!find model -name adapter_config.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Parche opcional (si falla por `alora_invocation_tokens`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "cfg_path = 'model/qwen3-jupyter-lora/adapter_config.json'\n",
        "if os.path.exists(cfg_path):\n",
        "    with open(cfg_path) as f:\n",
        "        cfg = json.load(f)\n",
        "    if 'alora_invocation_tokens' in cfg:\n",
        "        cfg.pop('alora_invocation_tokens', None)\n",
        "        with open(cfg_path, 'w') as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        print('patched', cfg_path)\n",
        "    else:\n",
        "        print('no patch needed')\n",
        "else:\n",
        "    print('adapter_config.json not found, check LORA_PATH')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Cargar modelo base + LoRA y generar ejercicio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "BASE_MODEL = 'Qwen/Qwen3-4B-Instruct-2507'\n",
        "LORA_PATH = './model/qwen3-jupyter-lora'\n",
        "SCHEMA = r'''{\"title\":\"...\",\"instructions\":\"...\",\"starterCode\":\"...\",\"solutionCode\":\"...\",\"expectedOutput\":\"...\",\"hints\":[\"...\",\"...\"],\"files\":[{\"filename\":\"...\",\"description\":\"...\",\"columns\":[\"...\"]}],\"steps\":[\"...\"],\"acceptanceCriteria\":[\"...\"]}'''\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    device_map='auto',\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
        "model.eval()\n",
        "\n",
        "def build_prompt(topic, difficulty, exercise_type, dataset_size):\n",
        "    return '\\n'.join([\n",
        "        'You are an expert instructor creating beginner-friendly Jupyter exercises.',\n",
        "        'Return ONLY valid JSON, no markdown fences, no extra commentary.',\n",
        "        'Use exactly this schema:',\n",
        "        SCHEMA,\n",
        "        'All text must be in Spanish. hints must be an array with 2 to 4 items.',\n",
        "        f'- topic: {topic}',\n",
        "        f'- difficulty: {difficulty}',\n",
        "        f'- exerciseType: {exercise_type}',\n",
        "        f'- datasetSize: {dataset_size}',\n",
        "    ])\n",
        "\n",
        "prompt = build_prompt('pandas','basica','completar_codigo','pequeno')\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.inference_mode():\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=96,\n",
        "        temperature=0.2,\n",
        "        top_p=0.7,\n",
        "        do_sample=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "    )\n",
        "\n",
        "gen = tokenizer.decode(output[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "print(gen[:600])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Validar JSON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = gen.strip()\n",
        "print('raw preview:', text[:300])\n",
        "start, end = text.find('{'), text.rfind('}')\n",
        "def build_fallback(kv):\n",
        "    return {\n",
        "        'title': 'Ejercicio de pandas (basica)',\n",
        "        'instructions': 'Practica pandas con dificultad basica.\\nTipo de actividad: completar_codigo.\\nTrabaja con un dataset de tamano pequeno (~40 filas).',\n",
        "        'starterCode': \"import pandas as pd\\n\\ndf = pd.read_csv('datos_practica.csv')\\n# TODO: completa la solucion\\ndf.head()\\n\",\n",
        "        'solutionCode': \"import pandas as pd\\n\\ndf = pd.read_csv('datos_practica.csv')\\nresumen = df.groupby('categoria')['ventas'].mean().sort_values(ascending=False)\\nprint(resumen)\\n\",\n",
        "        'expectedOutput': 'Serie con promedio de ventas por categoria ordenada de mayor a menor.',\n",
        "        'hints': [\n",
        "            'Verifica que el archivo cargue sin columnas nulas inesperadas.',\n",
        "            'Descompone el problema en pasos pequenos y validables.',\n",
        "            'Compara tu salida con el criterio de aceptacion.',\n",
        "        ],\n",
        "        'files': [\n",
        "            {\n",
        "                'filename': 'datos_practica.csv',\n",
        "                'description': kv.get('datasetDescription', 'Dataset de ventas de productos en una tienda local'),\n",
        "                'columns': ['id','fecha','categoria','ventas','costo'],\n",
        "            }\n",
        "        ],\n",
        "        'steps': [\n",
        "            'Carga el archivo de datos y revisa columnas y tipos.',\n",
        "            'Aplica la operacion solicitada segun el tema.',\n",
        "            'Muestra la salida final y valida que sea consistente.',\n",
        "        ],\n",
        "        'acceptanceCriteria': [\n",
        "            'El codigo se ejecuta sin errores.',\n",
        "            'La salida cumple el objetivo del ejercicio.',\n",
        "            'El resultado usa correctamente las columnas esperadas.',\n",
        "        ],\n",
        "    }\n",
        "\n",
        "if start == -1 or end == -1 or end <= start:\n",
        "    print('No JSON object found, using fallback.')\n",
        "    kv = {}\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line or ':' not in line:\n",
        "            continue\n",
        "        if line.startswith('-'): line = line[1:].strip()\n",
        "        k, v = line.split(':', 1)\n",
        "        kv[k.strip()] = v.strip()\n",
        "    payload = build_fallback(kv)\n",
        "else:\n",
        "    try:\n",
        "        payload = json.loads(text[start:end+1])\n",
        "        print('JSON ok')\n",
        "    except json.JSONDecodeError:\n",
        "        print('JSON invalid, using fallback.')\n",
        "        kv = {}\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if not line or ':' not in line:\n",
        "                continue\n",
        "            if line.startswith('-'): line = line[1:].strip()\n",
        "            k, v = line.split(':', 1)\n",
        "            kv[k.strip()] = v.strip()\n",
        "        payload = build_fallback(kv)\n",
        "\n",
        "payload\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}